{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrSimple07/KMU_application/blob/main/prompt_stability_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9cf4c3-c264-4947-97f4-36db8e431deb",
      "metadata": {
        "id": "6d9cf4c3-c264-4947-97f4-36db8e431deb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Vikhrmodels/Vikhr-7B-instruct_merged\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Vikhrmodels/Vikhr-7B-instruct_merged\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f90663-1b12-4e81-8c9e-7bf832de1c7f",
      "metadata": {
        "id": "d8f90663-1b12-4e81-8c9e-7bf832de1c7f",
        "outputId": "66ec91cd-baf3-406a-f5a0-89a39194a811",
        "colab": {
          "referenced_widgets": [
            "72af29531cec4cce829c54a7adcb0657"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72af29531cec4cce829c54a7adcb0657",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"Vikhrmodels/Vikhr-7B-instruct_merged\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0edaa59-6169-450e-b59f-ccd8488b7a7c",
      "metadata": {
        "id": "c0edaa59-6169-450e-b59f-ccd8488b7a7c"
      },
      "outputs": [],
      "source": [
        "# TODO: add more templates here, including the original one\n",
        "chegeka_prompt_collection = [\n",
        "    PromptTemplate(input_variables=[\"topic\", \"text\"],\n",
        "                   template='''Вы участвуете в викторине \"Что? Где? Когда?\". Внимательно прочитайте вопрос из категории \\\n",
        "\"{topic}\" и ответьте на него. Обратите внимание на формат ответа: если он не указан в вопросе, \\\n",
        "то запишите только слово или фразу, отвечающую на вопрос, никаких дополнительных рассуждений приводить не нужно.\n",
        "Вопрос: {text}\n",
        "Ответ: '''),\n",
        "    PromptTemplate(input_variables=[\"topic\", \"text\"],\n",
        "                  template= '''Прочитайте вопрос из категории \"{topic}\" и ответьте на него: {text}\n",
        "Ответ: '''),\n",
        "    PromptTemplate(input_variables=[\"topic\", \"text\"],\n",
        "                   template='''Вы участвуете в викторине \"Что? Где? Когда?\". Внимательно прочитайте вопрос из категории \"{topic}\" и ответьте на него. Обратите внимание на формат ответа: если он не указан в вопросе, то запишите только слово или фразу, отвечающую на вопрос, никаких дополнительных рассуждений приводить не нужно.\n",
        "Вопрос: {text}\n",
        "Ответ: ''')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90009bab-4d42-4c9d-9b14-f095f61a924c",
      "metadata": {
        "id": "90009bab-4d42-4c9d-9b14-f095f61a924c"
      },
      "outputs": [],
      "source": [
        "# TODO: create a collection of sampled tasks\n",
        "\n",
        "chegeka_task_collection = [\n",
        "    {'text':'Продолжение этого фильма Евгения Матвеева называется', 'topic': 'Любовь'},\n",
        "    {'text': 'С ЭТИМ ЧЕЛОВЕКОМ, 33-м потомком Нина, Державин сравнивает богатого и ленивого вельможу.', 'topic': 'Гласные - только \"А\"'},\n",
        "    {'text': 'По мнению древнего мудреца Рюхейб-бин-Верда: \"Мудрость состоит из 10 частей. Одна часть — знания и опыт.\" А что составляет остальные девять?', 'topic': 'Восток - дело тонкое'}\n",
        "]\n",
        "\n",
        "chegeka_collection_answers = [\n",
        "    {'answer': 'Любовь земная'},\n",
        "    {'answer': 'Сарданапал'},\n",
        "    {'answer': 'Молчание'}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e5b4853-92c0-4ca1-a5ee-6e6b53dacbbb",
      "metadata": {
        "id": "0e5b4853-92c0-4ca1-a5ee-6e6b53dacbbb"
      },
      "outputs": [],
      "source": [
        "# you should use generation method with temperature, i put pipeline here just for example\n",
        "def process_texts(prompt_collection, task_collection, pipe):\n",
        "    for task in task_collection:\n",
        "        '================ Starting new task ================='\n",
        "        for prompt in prompt_collection:\n",
        "            # TODO: save all results to csv dataframe (question, text, prompt, answer)\n",
        "            # for instruction models may be special tokens that should be included in the prompt\n",
        "            print(pipe(prompt.format(**task), return_full_text=False, max_new_tokens=100))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67269de-5f6c-49d8-880a-be765aa57bad",
      "metadata": {
        "id": "f67269de-5f6c-49d8-880a-be765aa57bad",
        "outputId": "29441e45-6e6e-4ac4-c8ce-b6eaa236ba6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '200 летней ночи.\\n\\nВот и все, у вас есть ответ на этот вопрос. Если вам интересно узнать, как выглядит ответ на вопрос, который вы не знали, то вы можете найти его в разделе \"Ответы\".\\n\\nЕсли у вас возникли вопросы или предложения по улучшению этого сайта, то вы можете написать нам на почту admin@victorina.club. Мы всегда рады услышать ваши комментарии и предложения.\\n\\nСнова'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '20 лет спустя.\\n\\nВот и все! Если у вас возникли вопросы, пишите в комментариях. Удачи! :)'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '200 летней ночи.\\n\\nВот и все, у вас есть ответ на этот вопрос. Если вам интересно узнать, как выглядит ответ на вопрос, который вы не знали, то вы можете найти его в разделе \"Ответы\".\\n\\nЕсли у вас возникли вопросы или предложения по улучшению этого сайта, то вы можете написать нам на почту admin@victorina.club. Мы всегда рады услышать ваши комментарии и предложения.\\n\\nСнова'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '33-мтом.\\n\\nНажмите на \"Далее\" для перехода к следующему вопросу.'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '33-м потомком Нина, Державин сравнивает богатого и ленивого вельможу.\\n\\nС ЭТИМ ЧЕЛВОЕКОМ, 33-мтомком Нина, Державин сравнивает богатого и ленивого вельможу.\\n\\nС ЭТИМ ЧЕ ЛОЕКОМ, 33-мтомком Нина, Державин сравнивает богатого и'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '33-мтом.\\n\\nНажмите на \"Далее\" для перехода к следующему вопросу.'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '1. Умение слушать; 2. Умение говорить; 3. Умение читать; 4. Умение писать; 5. Умение думать; 6. Умение работать; 7. Умение служить; 8. Умение успокаиваться; 9. Умение умирать.\\n\\nЕсли вам интересно узнать ответ на следующий вопрос, напишите его в комментариях и я'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': '1. Умение слушать; 2. Умение говорить; 3. Умение читать; 4. Умение писать; 5. Умение думать; 6. Умение работать; 7. Умение жить; 8. Умение умирать; 9. Умение быть мудрым.\\n\\n## Понимание вопроса\\n\\nВ этом вопросе мы просим вас понять, что такое'}]\n",
            "[{'generated_text': '1. Умение слушать; 2. Умение говорить; 3. Умение читать; 4. Умение писать; 5. Умение думать; 6. Умение работать; 7. Умение служить; 8. Умение успокаиваться; 9. Умение умирать.\\n\\nЕсли вам интересно узнать ответ на следующий вопрос, напишите его в комментариях и я'}]\n"
          ]
        }
      ],
      "source": [
        "process_texts(chegeka_prompt_collection, chegeka_task_collection, pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e412c371-8dfc-4981-9b44-9d93e15bf8d1",
      "metadata": {
        "id": "e412c371-8dfc-4981-9b44-9d93e15bf8d1"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# 1. measure answer correctness (metric from original benchmark, the same as they measure) for each of the tasks with different prompts\n",
        "# 2. measure answer variability (metric(s) is up to you to propose) for a task depending on a prompt\n",
        "# ----- upper two tasks for initial KMU application\n",
        "# 3. take LIME (or other method for interpreting the dependence of the answer on input) and analyze why answers are different"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}